{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f0d88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'label'],\n",
      "        num_rows: 116722\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'label'],\n",
      "        num_rows: 6553\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['prompt', 'label'],\n",
      "        num_rows: 6447\n",
      "    })\n",
      "})\n",
      "{'prompt': 'SUBREDDIT: r/relationships\\nTITLE: To admit or not to admit snooping...\\nPOST: I [25M] have snooped in the past and copped up to it to my gf [25F] of 6 years.  We talked it through.  It had been a year or two since the last time.  That\\'s an issue I\\'m working on.\\n\\nNow she has a new close male work friend.  I won\\'t go into details, but she hides things from me with him and does other things to make me a bit suspicious.  So...I snooped again, and this time, all texts from her new friend have been deleted and I saw a google search for \"how to get over a guy\" near some searches of his name and views of his Facebook profile.\\n\\nI asked her about this guy, not mentioning the snooping, and she denied any feelings, we talked for a long time about our relationship and she insisted that she only loves me and I mean the world to her, and that she really wants to work towards getting this relationship back out of the rut we\\'ve been in (we both work all the time and barely see each other).\\n\\nI think if I cop to the snooping, we might have a more honest conversation about what\\'s actually going on (if something is) and why she\\'s having these feelings so we can either work through it together (my preference) or move on.  But obviously, it will open the pandora\\'s box of the snooping.\\n\\nThink it\\'s worth it to admit to the snooping to hopefully get to the bottom of this?', 'chosen': 'TL;DR:  Snooped, found something, should I admit what I found so we can have a more honest conversation about it with less denial on her part?', 'rejected': \"TL;DR:  I snooped, we talked about it, she wants to work it out, I'm not sure.  Is the snooping worth it?\"}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# This will download the dataset and load it\n",
    "tldr_dataset = load_dataset(\"CarperAI/openai_summarize_tldr\")\n",
    "\n",
    "# To see the available splits\n",
    "print(tldr_dataset)\n",
    "\n",
    "# To access the train split, for example:\n",
    "tldr_train_data = tldr_dataset[\"train\"]\n",
    "print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb677104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 92534\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 83629\n",
      "    })\n",
      "    valid1: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 33082\n",
      "    })\n",
      "    valid2: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 50715\n",
      "    })\n",
      "})\n",
      "{'prompt': 'SUBREDDIT: r/relationships\\nTITLE: To admit or not to admit snooping...\\nPOST: I [25M] have snooped in the past and copped up to it to my gf [25F] of 6 years.  We talked it through.  It had been a year or two since the last time.  That\\'s an issue I\\'m working on.\\n\\nNow she has a new close male work friend.  I won\\'t go into details, but she hides things from me with him and does other things to make me a bit suspicious.  So...I snooped again, and this time, all texts from her new friend have been deleted and I saw a google search for \"how to get over a guy\" near some searches of his name and views of his Facebook profile.\\n\\nI asked her about this guy, not mentioning the snooping, and she denied any feelings, we talked for a long time about our relationship and she insisted that she only loves me and I mean the world to her, and that she really wants to work towards getting this relationship back out of the rut we\\'ve been in (we both work all the time and barely see each other).\\n\\nI think if I cop to the snooping, we might have a more honest conversation about what\\'s actually going on (if something is) and why she\\'s having these feelings so we can either work through it together (my preference) or move on.  But obviously, it will open the pandora\\'s box of the snooping.\\n\\nThink it\\'s worth it to admit to the snooping to hopefully get to the bottom of this?', 'chosen': 'TL;DR:  Snooped, found something, should I admit what I found so we can have a more honest conversation about it with less denial on her part?', 'rejected': \"TL;DR:  I snooped, we talked about it, she wants to work it out, I'm not sure.  Is the snooping worth it?\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset(\"CarperAI/openai_summarize_comparisons\")\n",
    "\n",
    "# To see the available splits\n",
    "print(dataset)\n",
    "\n",
    "# To access the train split, for example:\n",
    "summarize_train_data = dataset[\"train\"]\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e9a2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B-Base\"  # Replace with Qwen3 if available\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0c9be75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBREDDIT: r/relationships\n",
      "TITLE: I (f/22) have to figure out if I want to still know these girls or not and would hate to sound insulting\n",
      "POST: Not sure if this belongs here but it's worth a try. \n",
      "\n",
      "Backstory:\n",
      "When I (f/22) went through my first real breakup 2 years ago because he needed space after a year of dating roand  it effected me more than I thought. It was a horrible time in my life due to living with my mother and finally having the chance to cut her out of my life. I can admit because of it was an emotional wreck and this guy was stable and didn't know how to deal with me. We ended by him avoiding for a month or so after going to a festival with my friends. When I think back I wish he just ended. So after he ended it added my depression I suffered but my friends helped me through it and I got rid of everything from him along with cutting contact. \n",
      "\n",
      "Now: Its been almost 3 years now and I've gotten better after counselling and mild anti depressants. My mother has been out of my life since then so there's been alot of progress. Being stronger after learning some lessons there been more insight about that time of my life but when I see him or a picture everything comes back. The emotions and memories bring me back down. \n",
      "\n",
      "His friends (both girls) are on my facebook because we get along well which is hard to find and I know they'll always have his back. But seeing him in a picture or talking to him at a convention having a conversation is tough. Crying confront of my current boyfriend is something I want to avoid. \n",
      "\n",
      "So I've been thinking that I have to cut contact with these girls because it's time to move on because it's healthier. It's best to avoid him as well. But will they be insulted? Will they accept it? Is there going to be awkwardness? I'm not sure if it's the right to do and could use some outside opinions.\n",
      "TL;DR: \n",
      "I still have contact with an old ex's friends but can't stand to see or talk to him. His friends are really nice ,so how do I tell them I possibly want to unfriend them on Facebook because of him?\n",
      "----------------------------------------\n",
      "SUBREDDIT: r/loseit\n",
      "TITLE: SV & NSV! Keeping on keeping on.\n",
      "POST: 30F, 5'6\". SW: 236 GW: 150 CW: 219\n",
      "\n",
      "I weigh myself weekly and measure myself monthly. I'd hit a plateau the last four weeks or so where I was stuck at 222. Felt like kind of a bummer, but knew it's because I haven't been as strict as I should with my diet, and the last week and a half have been crazy with life things, so I haven't been exercising as frequently as I've gotten used to. When I weighed myself as normal on Monday, I was kind of disappointed to see the scale not budging and figured it was time to buckle down again and really watch my diet. Today was my measure-in day, and I've felt cruddy in general since Monday because I caught some chest congestion/cold bug over the weekend. I get on the scale...it says 219. Whaaaaat? I take my measurements, which are down slightly from last month, and with an total-body loss of 8 inches from my starting point on 12/23/14! Some of my clothes have been feeling a bit looser as of late and now I know it's just not in my head. I'm now the lightest and smallest I've been since right around high school!\n",
      "TL;DR: \n",
      "Progress is still happening, even when you think it might not be! Don't get discouraged, even if your journey seems to be going slowly. Don't give up, warriors.\n",
      "----------------------------------------\n",
      "SUBREDDIT: r/relationships\n",
      "TITLE: Me [19F] with my friend [19M] 10 months, Insecurities - Show or Tell?\n",
      "POST: What are your stories about insecurities you've had in past relationships? How have you dealt with them, particularly the ones that you can't hide?\n",
      "\n",
      "I'm not currently in a relationship, but recently I've realized that there is someone who likes me, and I'm interested in them, too. Frankly, the only reason I'm not asking them out is because I know that I have some insecurities that need to be worked through - particularly in the realm of body image. While I'm confident in the rest of my body, I've had terrible, awful acne both on my arms and breasts since I was very young. It's a special type with no complete cure, but doctors suggested that I keep my skin oiled until it goes away (dryness irritates it). Because of this it's not so much present anymore as large clusters of scars are.\n",
      "\n",
      "Would I warn someone about this upfront before anything sexual? Would I just let it surprise them when the clothes come off? Do I tell them \"Let's keep on my shirt for now\" while we do our business? \n",
      "\n",
      "Have you had experiences with anything similar? I want to hear how they went!\n",
      "TL;DR: \n",
      "My skin is scarred badly; what could I do/say about it that would gross my future partner out the least? What's your experience with body image issues?\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print a few examples\n",
    "for i in range(3):\n",
    "    print(tldr_dataset[\"train\"][i][\"prompt\"])\n",
    "    print(tldr_dataset[\"train\"][i][\"label\"])\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e98428a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 116722/116722 [01:34<00:00, 1230.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(example):\n",
    "    # You can add a prompt if you want, e.g., \"Summarize: \"\n",
    "    input_text = example[\"prompt\"]\n",
    "    target_text = example[\"label\"]\n",
    "    model_inputs = tokenizer(\n",
    "        input_text, max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        target_text, max_length=64, truncation=True, padding=\"max_length\"\n",
    "    )[\"input_ids\"]\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = tldr_dataset[\"train\"].map(preprocess_function, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee784f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosh/mlx-summariser/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 0 Loss: 3.8355\n",
      "Epoch 0 Batch 10 Loss: 2.5739\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 47\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/mlx-summariser/.venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlx-summariser/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"Qwen/Qwen1.5-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Prepare a small dataset for demonstration\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"CarperAI/openai_summarize_tldr\", split=\"train[:1000]\")  # Use a small subset for speed\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Concatenate prompt and label for each example\n",
    "    input_texts = [x[\"prompt\"] + \"\\nTL;DR: \" + x[\"label\"] for x in batch]\n",
    "    # Tokenize the concatenated text\n",
    "    encodings = tokenizer(\n",
    "        input_texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "    # For SFT, labels are the same as input_ids\n",
    "    labels = encodings[\"input_ids\"].clone()\n",
    "    encodings = {k: v.to(device) for k, v in encodings.items()}\n",
    "    labels = labels.to(device)\n",
    "    return encodings, labels\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(1):  # 1 epoch for demo\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch {epoch} Batch {batch_idx} Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60f59c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53.2\n",
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "import transformers, accelerate\n",
    "print(transformers.__version__)\n",
    "print(accelerate.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
